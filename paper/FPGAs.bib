
@article{istvan_caribou_2017,
  title      = {Caribou: intelligent distributed storage},
  volume     = {10},
  issn       = {2150-8097},
  shorttitle = {Caribou},
  url        = {https://doi.org/10.14778/3137628.3137632},
  doi        = {10.14778/3137628.3137632},
  abstract   = {The ever increasing amount of data being handled in data centers causes an intrinsic inefficiency: moving data around is expensive in terms of bandwidth, latency, and power consumption, especially given the low computational complexity of many database operations.In this paper we explore near-data processing in database engines, i.e., the option of offloading part of the computation directly to the storage nodes. We implement our ideas in Caribou, an intelligent distributed storage layer incorporating many of the lessons learned while building systems with specialized hardware. Caribou provides access to DRAM/NVRAM storage over the network through a simple key-value store interface, with each storage node providing high-bandwidth near-data processing at line rate and fault tolerance through replication. The result is a highly efficient, distributed, intelligent data storage that can be used to both boost performance and reduce power consumption and real estate usage in the data center thanks to the micro-server architecture adopted.},
  number     = {11},
  urldate    = {2025-01-27},
  journal    = {Proc. VLDB Endow.},
  author     = {István, Zsolt and Sidler, David and Alonso, Gustavo},
  month      = aug,
  year       = {2017},
  pages      = {1202--1213}
}

@article{istvan_glass_2019,
  title   = {The {Glass} {Half} {Full}: {Using} {Programmable} {Hardware} {Accelerators} in {Analytics}.},
  volume  = {42},
  number  = {1},
  journal = {IEEE Data Eng. Bull.},
  author  = {István, Zsolt},
  year    = {2019},
  pages   = {49--60}
}

@inproceedings{li_bitweaving_2013,
  address    = {New York, NY, USA},
  series     = {{SIGMOD} '13},
  title      = {{BitWeaving}: fast scans for main memory data processing},
  isbn       = {978-1-4503-2037-5},
  shorttitle = {{BitWeaving}},
  url        = {https://doi.org/10.1145/2463676.2465322},
  doi        = {10.1145/2463676.2465322},
  abstract   = {This paper focuses on running scans in a main memory data processing system at "bare metal" speed. Essentially, this means that the system must aim to process data at or near the speed of the processor (the fastest component in most system configurations). Scans are common in main memory data processing environments, and with the state-of-the-art techniques it still takes many cycles per input tuple to apply simple predicates on a single column of a table. In this paper, we propose a technique called BitWeaving that exploits the parallelism available at the bit level in modern processors. BitWeaving operates on multiple bits of data in a single cycle, processing bits from different columns in each cycle. Thus, bits from a batch of tuples are processed in each cycle, allowing BitWeaving to drop the cycles per column to below one in some case. BitWeaving comes in two flavors: BitWeaving/V which looks like a columnar organization but at the bit level, and BitWeaving/H which packs bits horizontally. In this paper we also develop the arithmetic framework that is needed to evaluate predicates using these BitWeaving organizations. Our experimental results show that both these methods produce significant performance benefits over the existing state-of-the-art methods, and in some cases produce over an order of magnitude in performance improvement.},
  urldate    = {2025-01-20},
  booktitle  = {Proceedings of the 2013 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
  publisher  = {Association for Computing Machinery},
  author     = {Li, Yinan and Patel, Jignesh M.},
  month      = jun,
  year       = {2013},
  pages      = {289--300}
}

@inproceedings{lisa_column_2018,
  title     = {Column {Scan} {Acceleration} in {Hybrid} {CPU}-{FPGA} {Systems}.},
  booktitle = {{ADMS}@ {VLDB}},
  author    = {Lisa, Nusrat Jahan and Ungethüm, Annett and Habich, Dirk and Lehner, Wolfgang and Nguyen, Tuan DA and Kumar, Akash},
  year      = {2018},
  pages     = {22--33}
}


@inproceedings{sidler_accelerating_2017,
  address   = {New York, NY, USA},
  series    = {{SIGMOD} '17},
  title     = {Accelerating {Pattern} {Matching} {Queries} in {Hybrid} {CPU}-{FPGA} {Architectures}},
  isbn      = {978-1-4503-4197-4},
  url       = {https://doi.org/10.1145/3035918.3035954},
  doi       = {10.1145/3035918.3035954},
  abstract  = {Taking advantage of recently released hybrid multicore architectures, such as the Intel's Xeon+FPGA machine, where the FPGA has coherent access to the main memory through the QPI bus, we explore the benefits of specializing operators to hardware. We focus on two commonly used SQL operators for strings: LIKE, and REGEXP\_LIKE, and provide a novel and efficient implementation of these operators in reconfigurable hardware. We integrate the hardware accelerator into MonetDB, a main-memory column store, and demonstrate a significant improvement in response time and throughput. Our Hardware User Defined Function (HUDF) can speed up complex pattern matching by an order of magnitude in comparison to the database running on a 10-core CPU. The insights gained from integrating hardware based string operators into MonetDB should also be useful for future designs combining hardware specialization and databases.},
  urldate   = {2025-01-20},
  booktitle = {Proceedings of the 2017 {ACM} {International} {Conference} on {Management} of {Data}},
  publisher = {Association for Computing Machinery},
  author    = {Sidler, David and István, Zsolt and Owaida, Muhsen and Alonso, Gustavo},
  month     = may,
  year      = {2017},
  pages     = {403--415}
}

@misc{wikipedia_pipeline,
  author       = {Cburnett},
  title        = {Generic 4-stage pipeline},
  howpublished = {\url{https://en.wikipedia.org/wiki/Instruction_pipelining#/media/File:Pipeline,_4_stage.svg}},
  note         = {Zugriff: 24-Jan-2025}
}